{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyHDwD4tyj6ffxEhjAfn9c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajnish80130/bias-variance-tradeoff/blob/main/bias_variance_tradeoff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bias Variance Tradeoff\n",
        "If the algorithm is too simple (hypothesis with linear equation) then it may be on high bias and low variance condition and thus is error-prone. If algorithms fit too complex (hypothesis with high degree equation) then it may be on high variance and low bias. In the latter condition, the new entries will not perform well. Well, there is something between both of these conditions, known as a Trade-off or Bias Variance Trade-off. This tradeoff in complexity is why there is a tradeoff between bias and variance. An algorithm canâ€™t be more complex and less complex at the same time. For the graph, the perfect tradeoff will be like this."
      ],
      "metadata": {
        "id": "Gf2mp6HpjsIW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuRAgraIjHJV",
        "outputId": "2a67e56a-aa18-474b-a9af-026352c46a1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.501952"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "outcome = []\n",
        "for i in range(1000000):\n",
        "  outcome.append(random.randint(1,6))\n",
        "\n",
        "np.array(outcome).mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.evaluate import bias_variance_decomp\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from mlxtend.data import boston_housing_data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X, y = boston_housing_data()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=123,\n",
        "                                                    shuffle=True)"
      ],
      "metadata": {
        "id": "CXdIomEYj1RM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression()\n",
        "\n",
        "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
        "        lr, X_train, y_train, X_test, y_test,\n",
        "        loss='mse',\n",
        "        random_seed=123)\n",
        "\n",
        "print('Average expected loss: %.3f' % avg_expected_loss)\n",
        "print('Average bias: %.3f' % avg_bias)\n",
        "print('Average variance: %.3f' % avg_var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7eG3_hSj1UV",
        "outputId": "1a704ecf-98bb-4589-d251-a96ca66ce743"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average expected loss: 29.891\n",
            "Average bias: 28.609\n",
            "Average variance: 1.282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeRegressor(random_state=123)\n",
        "\n",
        "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
        "        dt, X_train, y_train, X_test, y_test,\n",
        "        loss='mse',\n",
        "        random_seed=123)\n",
        "\n",
        "print('Average expected loss: %.3f' % avg_expected_loss)\n",
        "print('Average bias: %.3f' % avg_bias)\n",
        "print('Average variance: %.3f' % avg_var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HI1fd9Rj1ai",
        "outputId": "d12c9d74-47a1-45e4-92be-ba984b607ee4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average expected loss: 31.536\n",
            "Average bias: 14.096\n",
            "Average variance: 17.440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4XYV5KU3kZ72"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}